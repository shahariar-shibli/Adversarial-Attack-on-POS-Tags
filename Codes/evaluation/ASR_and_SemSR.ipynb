{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633713a2",
      "metadata": {
        "id": "633713a2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ce3cb8",
      "metadata": {
        "id": "10ce3cb8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install transformers\n",
        "!pip3 install emoji\n",
        "!pip3 install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949ca546",
      "metadata": {
        "id": "949ca546"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66310791",
      "metadata": {
        "id": "66310791"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "\n",
        "# Load the pre-trained CLIP model and the image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-L/14@336px')\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "def get_clip_score(image, text):\n",
        "\n",
        "    # Preprocess the image and tokenize the text\n",
        "    image_input = preprocess(image).unsqueeze(0)\n",
        "    text_input = clip.tokenize([text])\n",
        "\n",
        "    # Move the inputs to GPU if available\n",
        "    image_input = image_input.to(device)\n",
        "    text_input = text_input.to(device)\n",
        "\n",
        "    # Generate embeddings for the image and text\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image_input)\n",
        "        text_features = model.encode_text(text_input)\n",
        "\n",
        "    # Normalize the features\n",
        "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # Calculate the cosine similarity to get the CLIP score\n",
        "    clip_score = torch.matmul(image_features, text_features.T).item()\n",
        "\n",
        "    return clip_score*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc56ef1",
      "metadata": {
        "id": "7bc56ef1"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 3.41\n",
        "matches = 0\n",
        "total = 0\n",
        "NUM_IMAGES = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d210735f",
      "metadata": {
        "id": "d210735f",
        "outputId": "93e326cc-03d2-452c-994c-1fe542f4c61b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./PROP NOUN/\n"
          ]
        }
      ],
      "source": [
        "root = \"./PROP NOUN/\"\n",
        "df = pd.read_csv(root+\"PROPNOUN_prompt_pairs_100.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1793911b",
      "metadata": {
        "id": "1793911b"
      },
      "outputs": [],
      "source": [
        "for j in range(len(df)):\n",
        "    input_text = df[\"input_prompt\"][j]\n",
        "    target_text = df[\"target_prompt\"][j]\n",
        "\n",
        "    dir_path = root+input_text.replace(\" \",\"_\").replace(\".\",\"_\")+\"___\"+target_text.replace(\" \",\"_\").replace(\".\",\"_\")+\"/\"\n",
        "    sub_dir = os.listdir(dir_path)\n",
        "\n",
        "    with open(dir_path + \"/prompts.json\", \"r\") as f:\n",
        "        prompt = json.load(f)\n",
        "\n",
        "    prompts = []\n",
        "    for prm in prompt['adv_prompts']:\n",
        "        if emoji.emojize(prm) == input_text:\n",
        "            continue\n",
        "        prompts.append(emoji.emojize(prm))\n",
        "\n",
        "    total_avg_semSR = 0\n",
        "    idx = 0\n",
        "    success = 0\n",
        "    avg_semSR = 0\n",
        "    for dirs in sub_dir:\n",
        "        if dirs.startswith(\"prompt_\"):\n",
        "\n",
        "            text_outputs1, text_outputs2, prm_outputs = [], [], []\n",
        "            cnt = 0\n",
        "            for images in os.listdir(os.path.join(dir_path, dirs)):\n",
        "                if images.startswith(\"grid\"):\n",
        "                    continue\n",
        "                imagelist = Image.open(os.path.join(dir_path, dirs)+\"/\"+images)\n",
        "\n",
        "                inp_score = get_clip_score(imagelist, input_text)\n",
        "                tar_score = get_clip_score(imagelist, target_text)\n",
        "                prm_score = get_clip_score(imagelist, prompts[idx])\n",
        "\n",
        "                #print(inp_score, \" == \", tar_score)\n",
        "                prm_outputs.append(prm_score)\n",
        "                text_outputs1.append(inp_score)\n",
        "                text_outputs2.append(tar_score)\n",
        "                cnt = cnt + 1\n",
        "\n",
        "            idx = idx + 1\n",
        "            #print(cnt)\n",
        "            scores = []\n",
        "            semSR = 0\n",
        "            for i in range(cnt):\n",
        "                score = 0\n",
        "                if text_outputs2[i] - text_outputs1[i] >= THRESHOLD:\n",
        "                    score += 1\n",
        "                else:\n",
        "                    score -= 1\n",
        "                try:\n",
        "                    semSR += (prm_outputs[i] - text_outputs1[i])/(text_outputs2[i] - text_outputs1[i])\n",
        "                except ZeroDivisionError:\n",
        "                    semSR += 0\n",
        "\n",
        "                scores.append(score)\n",
        "\n",
        "            avg_semSR += semSR/cnt\n",
        "\n",
        "            vote = (cnt//2)+1\n",
        "            if scores.count(1) >= vote:\n",
        "                success += 1\n",
        "\n",
        "    try:\n",
        "        total_avg_semSR = avg_semSR/idx\n",
        "    except:\n",
        "        total_avg_semSR = 0\n",
        "\n",
        "    if success > 0:\n",
        "        prompt[\"success\"] = 1\n",
        "    else:\n",
        "        prompt[\"success\"] = 0\n",
        "\n",
        "    prompt[\"Avg SemSR\"] = total_avg_semSR\n",
        "    # print(j, \" , \", success, \" , \", total_avg_semSR)\n",
        "\n",
        "    with open(dir_path + \"/prompts.json\", \"w\") as f:\n",
        "        json.dump(prompt, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4375b25",
      "metadata": {
        "id": "a4375b25"
      },
      "outputs": [],
      "source": [
        "for_csv2 = {\n",
        "    \"input_text\": [],\n",
        "    \"target_text\": [],\n",
        "    \"success\": [],\n",
        "    \"semSR\":[]\n",
        "}\n",
        "\n",
        "for folder_name in os.listdir(root):\n",
        "    folder_name = os.path.join(root, folder_name)\n",
        "    if folder_name.endswith(\".csv\") or folder_name.endswith(\"checkpoints\"):\n",
        "        continue\n",
        "    prompt = None\n",
        "    with open(os.path.join(folder_name, 'prompts.json')) as f:\n",
        "        prompt = json.load(f)\n",
        "\n",
        "    for_csv2[\"input_text\"].append(prompt[\"input_text\"])\n",
        "    for_csv2[\"target_text\"].append(prompt[\"target_text\"])\n",
        "    for_csv2[\"success\"].append(prompt[\"success\"])\n",
        "    for_csv2[\"semSR\"].append(prompt[\"Avg SemSR\"])\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(for_csv2)\n",
        "\n",
        "df.to_csv(\"propnoun_clip_result.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}